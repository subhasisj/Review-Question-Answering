{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA System with Haystack and Elastic Search Backend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/28/2021 02:33:24 - INFO - elasticsearch -   HEAD http://localhost:9200/ [status:200 request:0.013s]\n",
      "11/28/2021 02:33:24 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.005s]\n",
      "11/28/2021 02:33:24 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.004s]\n",
      "11/28/2021 02:33:24 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.027s]\n",
      "11/28/2021 02:33:24 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.007s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(return_embedding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _By default, ElasticsearchDocumentStore creates two indices on Elasticsearch: one called document for (you guessed it) storing documents, and another called label for storing the annotated answer spans. For now, we’ll just populate the document index with the SubjQA reviews, and Haystack’s document stores expect a list of dictionaries with text and meta keys as follows:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/28/2021 02:33:35 - WARNING - datasets.load -   Using the latest cached version of the module from C:\\Users\\Subha\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\subjqa\\e5588f9298ff2d70686a00cc377e4bdccf4e32287459e3c6baf2dc5ab57fe7fd (last modified on Sun Nov  7 02:12:20 2021) since it couldn't be found locally at subjqa\\subjqa.py or remotely (ConnectionError).\n",
      "11/28/2021 02:33:35 - WARNING - datasets.builder -   Reusing dataset subjqa (C:\\Users\\Subha\\.cache\\huggingface\\datasets\\subjqa\\electronics\\1.1.0\\e5588f9298ff2d70686a00cc377e4bdccf4e32287459e3c6baf2dc5ab57fe7fd)\n"
     ]
    }
   ],
   "source": [
    "# Take each split of the SubjQA dataset and write to document_store\n",
    "from datasets import load_dataset\n",
    "\n",
    "subjqa_dataset = load_dataset(\"subjqa\", \"electronics\")\n",
    "subjqa_dataset.set_format(\"pandas\")\n",
    "\n",
    "dfs = {split: ds[:] for split, ds in subjqa_dataset.flatten().items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all reviews into Elasticsearch Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/28/2021 02:33:35 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.004s]\n",
      "11/28/2021 02:33:36 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.455s]\n",
      "11/28/2021 02:33:37 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.041s]\n",
      "11/28/2021 02:33:38 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.032s]\n",
      "11/28/2021 02:33:38 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.003s]\n",
      "11/28/2021 02:33:39 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.025s]\n",
      "11/28/2021 02:33:39 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.004s]\n",
      "11/28/2021 02:33:40 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.994s]\n",
      "11/28/2021 02:33:40 - INFO - elasticsearch -   POST http://localhost:9200/document/_count [status:200 request:0.006s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1615 documents\n"
     ]
    }
   ],
   "source": [
    "def write_documents(split, df):\n",
    "    docs = [\n",
    "        {\n",
    "            \"text\": row[\"context\"],\n",
    "            \"meta\": {\"item_id\": row[\"title\"], \"qid\": row[\"id\"], \"split\": split},\n",
    "        }\n",
    "        for _, row in df.drop_duplicates(subset=\"context\").iterrows()\n",
    "    ]\n",
    "    document_store.write_documents(docs, index=\"document\")\n",
    "\n",
    "\n",
    "for split, df in dfs.items():\n",
    "    write_documents(split, df)\n",
    "\n",
    "print(f\"Loaded {document_store.get_document_count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for reviews from Elasticsearch Index using Retriever\n",
    "\n",
    "> _The Elasticsearch document store can be paired with any of the Haystack retrievers\n",
    "BM25 is an improved version of the classic TF-IDF metric and represents the question and context as sparse vectors that can be searched efficiently on Elasticsearch. The BM25 score measures how much matched text is about a search query and improves on TF-IDF by saturating TF values quickly and normalizing the document length so that short documents are favoured over long ones._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "\n",
    "es_retriever = ElasticsearchRetriever(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/28/2021 02:33:40 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.013s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': \"From the limited time I've had to work with my Kindle, I'm extremely pleased.  The graphics are awesome, the size and weight is just right, speed is phenomenal.  My wife is jealous and she has an iPad 2.\", 'score': 0.6429956517280498, 'question': None, 'meta': {'item_id': 'B0074BW614', 'qid': '7e55bbbe23fe233278352936e5af66a0', 'split': 'train'}, 'embedding': None, 'id': '90f04ba41b1884aeab29eb73d297733'},\n",
       " {'text': 'Cannot believe what we have been missing. We are a tech family, and have been Ipad fans from the get go, have owned all three versions. Never even considered the Kindle until I saw one with no glare to read. So we thought for the price and Amazons great return policy why not try the new HD out and see how it is for reading.OH MY WORD......(mouth open) it is awesome. Reading books on this is like night and day to our Pads. The screen is rich and clear, the abilities to adjust things is great and love the being able to download books through Amazon right to the Kindle. Okay, that in itself was just grand, however being able to watch our movies through HDMI cords to our TV and download and shop with Amazon with such ease was such a nice treat. :)Yes, we still love our Pads and they have their own place, but I like that I can now keep my Pad at home and tote the Kindle around with me with so much ease..it is light weight, small and perfect for my purse. We like it so much we ordered another 7\" today, but with 32gb this time for me and hubby will use the 16gb one. We were waiting for the Mini Pad, but once we saw the specs and the screen pixelation, we came right to Amazon and ordered another Kindle Fire HD...Go figure..Goes to show you good things CAN come in small packages!! It\\'s light, fits in my hand and I can still do the daily stuff I used to do on Pad with it. Oh and did I mention some of the Apps are wayyyy cheaper on the Kindle than Apple? Same apps too...yes I do realize they do not need retina and such for the Kindle, but we don\\'t need that for a lot of the apps we use anyways.Get it...it works, it can go with you easier and it ROCKS!!', 'score': 0.6367934689730358, 'question': None, 'meta': {'item_id': 'B0074BW614', 'qid': '5a5cfbb2cb03e32853ec40f888daea61', 'split': 'train'}, 'embedding': None, 'id': '5dc8a02a7be1569d591072d6671c5eb1'},\n",
       " {'text': 'This was my daughters christmas gift this year. She has been so thrilled. This is a great tablet for her. I really struggled with which tablet to get for her. Yes she is 8 and its an extream gift, but we knew she would use it and take care of it. The tablet is made really well with a great feel to it. If it wasnt for an 8 year old i would not have bought a case for it, it just has that good of a feel to it.  I chose this tablet because it was for a child and i know there is only so much she would need it for. Mostly entertainment. Yes it is, in a sence, a way for amazon to get you to buy from them all kinds of media, but im happy with that. I love amazon. Everybody in the family knew she was receiving this for christmas so it made it easy for them to buy a gift card to excatly the place she would want one to. On a parent note...i chose this tablet for 2 deciding factors. One: its user friendly. I didnt have to spend an hour trying to figure out how to operate it. It came registered to my amazon account, and when i wanted to put my daughters name on the kindle instead of the name it came registered to ( mine) it was a snap. And those types of things usually take me forever to figure out. Everything on this device is very simple to use. I was worried how to swap things in and out of the cloud before i received it, but that also is so easy. You dont even have to think about it. Its plainly there and explains itself. So for anybody that wants a tablet but struggles with electronics and how to make them work right, this is for you. I wish all devices were this easy. The second deciding factor for me was the parental controls. And im not even using the free time feature. That adds even greater saftey and control even over how long your kids are allowed on it. But just from the standard functions i was able to set a passcode for turning wifi on, im able to block anything i want without locking everything as a whole. I can block just movies, or just the web, so thats why i went with the kindle,its the tablet she asked for, but it was a great choice. The ease of use and the great parental controls the other tablets didnt offer. The picture qualty is amazing, as well as the sound. They are not lying when they say these features are great. So this is just my 2 cents on my thoughts on this device for our 8 year old.  My daughter has also done more reading on this tablet in a week then she ever has, so its been very good for her on that end as well.', 'score': 0.588015329014527, 'question': None, 'meta': {'item_id': 'B0074BW614', 'qid': '040cd455a467b4d993f3758fd396979b', 'split': 'train'}, 'embedding': None, 'id': 'eb98498eef72cf2c8775430d7b8a8df3'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for sample query from reviews and filter by Item ID and split\n",
    "item_id = \"B0074BW614\"\n",
    "query = \"How is the weight?\"\n",
    "retrieval_results = es_retriever.retrieve(\n",
    "    query = query,top_k=3, filters={\"item_id\": [item_id], \"split\": [\"train\"]})\n",
    "\n",
    "\n",
    "retrieval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _We can now load all relevant documents using the Retreiver, we have to load the QA model and extract the answers for questions using the Reader_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load deepset/minilm-uncased-squad2 using FARMReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/28/2021 02:33:41 - INFO - farm.utils -   Using device: CUDA \n",
      "11/28/2021 02:33:41 - INFO - farm.utils -   Number of GPUs: 1\n",
      "11/28/2021 02:33:41 - INFO - farm.utils -   Distributed Training: False\n",
      "11/28/2021 02:33:41 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "11/28/2021 02:33:57 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "11/28/2021 02:33:57 - INFO - farm.utils -   Using device: CUDA \n",
      "11/28/2021 02:33:57 - INFO - farm.utils -   Number of GPUs: 1\n",
      "11/28/2021 02:33:57 - INFO - farm.utils -   Distributed Training: False\n",
      "11/28/2021 02:33:57 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "11/28/2021 02:33:57 - INFO - farm.infer -   Got ya 11 parallel workers to do inference ...\n",
      "11/28/2021 02:33:57 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0 \n",
      "11/28/2021 02:33:57 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "11/28/2021 02:33:57 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\\n",
      "11/28/2021 02:33:57 - INFO - farm.infer -                       \n",
      "11/28/2021 02:33:57 - INFO - farm.utils -   Using device: CUDA \n",
      "11/28/2021 02:33:57 - INFO - farm.utils -   Number of GPUs: 1\n",
      "11/28/2021 02:33:57 - INFO - farm.utils -   Distributed Training: False\n",
      "11/28/2021 02:33:57 - INFO - farm.utils -   Automatic Mixed Precision: None\n"
     ]
    }
   ],
   "source": [
    "from haystack.reader.farm import FARMReader\n",
    "\n",
    "model = \"deepset/minilm-uncased-squad2\"\n",
    "max_seq_length = 384\n",
    "doc_stride = 128\n",
    "\n",
    "reader = FARMReader(model_name_or_path=model,\n",
    "                 max_seq_len=max_seq_length,\n",
    "                 doc_stride=doc_stride,\n",
    "                 return_no_answer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.53 Batches/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How much music can it hold?',\n",
       " 'no_ans_gap': 13.045684576034546,\n",
       " 'answers': [{'answer': '1 MB/minute',\n",
       "   'score': 0.680178701877594,\n",
       "   'context': 'An MP3 is about 1 MB/minute, so about 6000 hours depending on file size.',\n",
       "   'offset_start': 16,\n",
       "   'offset_end': 27,\n",
       "   'offset_start_in_doc': 16,\n",
       "   'offset_end_in_doc': 27,\n",
       "   'document_id': 'e344757014e804eff50faa3ecf1c9c75'},\n",
       "  {'answer': None,\n",
       "   'score': 0.45309837548893656,\n",
       "   'context': None,\n",
       "   'offset_start': 0,\n",
       "   'offset_end': 0,\n",
       "   'document_id': None,\n",
       "   'meta': None}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How much music can it hold?\"\n",
    "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\n",
    "file size.\"\"\"\n",
    "\n",
    "reader.predict_on_texts(query, texts = [context],top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Haystack Pipelines for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, retriever=es_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Each Pipeline has a run function that specifies how the query flow should be executed. For ExtractiveQAPipeline we just need to pass the query, the number of documents to retrieve with top_k_retriever, and number of answers to extract from these documents with top_k_reader. In our case, we also need to specify a filter over the item ID which can be done using the filters argument as we did with the Retriever earlier._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/28/2021 02:32:15 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.024s]\n"
     ]
    }
   ],
   "source": [
    "item_id = \"B0074BW614\"\n",
    "query = \"Is it good for reading?\"\n",
    "n_answers = 3\n",
    "\n",
    "preds = pipe.run(\n",
    "    query=query,\n",
    "    params={\n",
    "        \"retriever\": {\"top_k\": 5},\n",
    "        \"reader\": {\"top_k\": n_answers},\n",
    "        \"filters\": {\"item_id\": [item_id], \"split\": [\"train\"]},\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Question: {query}\")\n",
    "for i in range(n_answers):\n",
    "    print(f\"Answer {i+1}: {preds['answers'][i]['answer']}\")\n",
    "    print(f\"Context: {preds['answers'][i]['context']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a447bb19d79f3db2674aacc85e780e48e431a75fa5f05809ae9b8d2d81dec273"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
